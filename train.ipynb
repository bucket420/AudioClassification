{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sounddevice as sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from utils import save_as_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = [\"acoustic\", \"electronic\", \"synthetic\"]\n",
    "families = [\"bass\", \"brass\", \"flute\", \"guitar\", \"keyboard\", \"mallet\", \"organ\", \"reed\", \"string\", \"synth_lead\", \"vocal\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrograms_train = tf.saved_model.load(\"data/processed/spectrograms_train\").read_value()\n",
    "spectrograms_test = tf.saved_model.load(\"data/processed/spectrograms_test\").read_value()\n",
    "labels_instr_train = tf.saved_model.load(\"data/processed/labels_instr_train\").read_value()\n",
    "labels_instr_test = tf.saved_model.load(\"data/processed/labels_instr_test\").read_value()\n",
    "labels_src_train = tf.saved_model.load(\"data/processed/labels_src_train\").read_value()\n",
    "labels_src_test = tf.saved_model.load(\"data/processed/labels_src_test\").read_value()\n",
    "audio_train = tf.saved_model.load(\"data/processed/audio_train\").read_value()\n",
    "audio_test = tf.saved_model.load(\"data/processed/audio_test\").read_value()\n",
    "audio_train = tf.expand_dims(audio_train, axis=-1)\n",
    "audio_test = tf.expand_dims(audio_test, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3072, 499, 129, 1)\n",
      "(3072,)\n",
      "(1024, 499, 129, 1)\n",
      "(1024,)\n",
      "(3072, 64000)\n",
      "(1024, 64000)\n"
     ]
    }
   ],
   "source": [
    "print(spectrograms_train.shape)\n",
    "print(labels_instr_train.shape)\n",
    "print(spectrograms_test.shape)\n",
    "print(labels_instr_test.shape)\n",
    "print(audio_train.shape)\n",
    "print(audio_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resizing (Resizing)         (None, 499, 129, 1)       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 497, 127, 16)      160       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 248, 63, 16)      0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 246, 61, 32)       4640      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 123, 30, 32)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 121, 28, 64)       18496     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 60, 14, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 60, 14, 64)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 53760)             0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 53760)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 11)                591371    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 614,667\n",
      "Trainable params: 614,667\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Norm = layers.Normalization()\n",
    "# Norm.adapt(spectrograms_train)\n",
    "\n",
    "model_instr_cnn = models.Sequential([\n",
    "    layers.Input(shape=(None, None, 1)),\n",
    "    layers.Resizing(*spectrograms_train.shape[1:-1]),\n",
    "    layers.Conv2D(16, 3, activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(32, 3, activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(64, 3, activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Dropout(0.25),\n",
    "    layers.Flatten(),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(len(families)),\n",
    "])\n",
    "\n",
    "model_instr_cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_instr_cnn.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "96/96 [==============================] - 17s 52ms/step - loss: 1.5385 - accuracy: 0.4766 - val_loss: 1.1308 - val_accuracy: 0.6162\n",
      "Epoch 2/50\n",
      "96/96 [==============================] - 4s 47ms/step - loss: 0.7969 - accuracy: 0.7214 - val_loss: 0.5631 - val_accuracy: 0.7998\n",
      "Epoch 3/50\n",
      "96/96 [==============================] - 4s 46ms/step - loss: 0.4928 - accuracy: 0.8330 - val_loss: 0.3595 - val_accuracy: 0.9033\n",
      "Epoch 4/50\n",
      "96/96 [==============================] - 4s 47ms/step - loss: 0.3656 - accuracy: 0.8704 - val_loss: 0.3438 - val_accuracy: 0.8916\n",
      "Epoch 5/50\n",
      "96/96 [==============================] - 4s 47ms/step - loss: 0.2865 - accuracy: 0.8994 - val_loss: 0.3009 - val_accuracy: 0.9023\n",
      "Epoch 6/50\n",
      "96/96 [==============================] - 4s 47ms/step - loss: 0.2332 - accuracy: 0.9147 - val_loss: 0.2609 - val_accuracy: 0.9365\n",
      "Epoch 7/50\n",
      "96/96 [==============================] - 4s 47ms/step - loss: 0.2011 - accuracy: 0.9307 - val_loss: 0.2151 - val_accuracy: 0.9355\n",
      "Epoch 8/50\n",
      "96/96 [==============================] - 4s 47ms/step - loss: 0.1818 - accuracy: 0.9417 - val_loss: 0.2571 - val_accuracy: 0.9365\n",
      "Epoch 9/50\n",
      "96/96 [==============================] - 4s 47ms/step - loss: 0.1760 - accuracy: 0.9430 - val_loss: 0.2144 - val_accuracy: 0.9434\n",
      "Epoch 10/50\n",
      "96/96 [==============================] - 4s 47ms/step - loss: 0.1357 - accuracy: 0.9616 - val_loss: 0.2858 - val_accuracy: 0.9453\n",
      "Epoch 11/50\n",
      "96/96 [==============================] - 4s 47ms/step - loss: 0.1217 - accuracy: 0.9600 - val_loss: 0.2631 - val_accuracy: 0.9453\n",
      "Epoch 12/50\n",
      "96/96 [==============================] - 4s 47ms/step - loss: 0.1210 - accuracy: 0.9583 - val_loss: 0.3032 - val_accuracy: 0.9443\n",
      "Epoch 13/50\n",
      "96/96 [==============================] - 4s 47ms/step - loss: 0.1532 - accuracy: 0.9580 - val_loss: 0.1789 - val_accuracy: 0.9590\n",
      "Epoch 14/50\n",
      "96/96 [==============================] - 4s 47ms/step - loss: 0.0963 - accuracy: 0.9717 - val_loss: 0.1704 - val_accuracy: 0.9668\n",
      "Epoch 15/50\n",
      "96/96 [==============================] - 4s 47ms/step - loss: 0.0849 - accuracy: 0.9701 - val_loss: 0.1686 - val_accuracy: 0.9600\n",
      "Epoch 16/50\n",
      "96/96 [==============================] - 4s 47ms/step - loss: 0.0630 - accuracy: 0.9801 - val_loss: 0.1816 - val_accuracy: 0.9648\n",
      "Epoch 17/50\n",
      "96/96 [==============================] - 4s 47ms/step - loss: 0.1247 - accuracy: 0.9639 - val_loss: 0.2193 - val_accuracy: 0.9492\n",
      "Epoch 18/50\n",
      "96/96 [==============================] - 4s 47ms/step - loss: 0.1102 - accuracy: 0.9648 - val_loss: 0.1664 - val_accuracy: 0.9600\n",
      "Epoch 19/50\n",
      "96/96 [==============================] - 4s 47ms/step - loss: 0.0699 - accuracy: 0.9782 - val_loss: 0.1535 - val_accuracy: 0.9639\n",
      "Epoch 20/50\n",
      "96/96 [==============================] - 4s 47ms/step - loss: 0.0908 - accuracy: 0.9701 - val_loss: 0.1539 - val_accuracy: 0.9658\n",
      "Epoch 21/50\n",
      "96/96 [==============================] - 4s 47ms/step - loss: 0.0570 - accuracy: 0.9801 - val_loss: 0.1856 - val_accuracy: 0.9756\n",
      "Epoch 22/50\n",
      "96/96 [==============================] - 5s 47ms/step - loss: 0.0592 - accuracy: 0.9785 - val_loss: 0.2234 - val_accuracy: 0.9502\n",
      "Epoch 23/50\n",
      "96/96 [==============================] - 4s 47ms/step - loss: 0.0512 - accuracy: 0.9818 - val_loss: 0.2509 - val_accuracy: 0.9678\n",
      "Epoch 24/50\n",
      "96/96 [==============================] - 4s 47ms/step - loss: 0.0496 - accuracy: 0.9840 - val_loss: 0.1752 - val_accuracy: 0.9727\n",
      "Epoch 24: early stopping\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 50\n",
    "history = model_instr_cnn.fit(\n",
    "    x=spectrograms_train,\n",
    "    y=labels_instr_train,\n",
    "    validation_data=(spectrograms_test, labels_instr_test),\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=tf.keras.callbacks.EarlyStopping(verbose=1, patience=5),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/instr_cnn\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/instr_cnn\\assets\n"
     ]
    }
   ],
   "source": [
    "save_as_json(history.history, \"training_history/instr_cnn.json\")\n",
    "model_instr_cnn.save(\"./models/instr_cnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resizing_2 (Resizing)       (None, 499, 129, 1)       0         \n",
      "                                                                 \n",
      " normalization_1 (Normalizat  (None, 499, 129, 1)      3         \n",
      " ion)                                                            \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 64371)             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 11)                708092    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 708,095\n",
      "Trainable params: 708,092\n",
      "Non-trainable params: 3\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_instr_lr = models.Sequential([\n",
    "    layers.Input(shape=(None, None, 1)),\n",
    "    layers.Resizing(*spectrograms_train.shape[1:-1]),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(len(families)),\n",
    "])\n",
    "\n",
    "model_instr_lr.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_instr_lr.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "96/96 [==============================] - 2s 14ms/step - loss: 7.0257 - accuracy: 0.4189 - val_loss: 5.6141 - val_accuracy: 0.4365\n",
      "Epoch 2/50\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 3.3819 - accuracy: 0.5938 - val_loss: 5.2932 - val_accuracy: 0.5195\n",
      "Epoch 3/50\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.4477 - accuracy: 0.6712 - val_loss: 4.7363 - val_accuracy: 0.6113\n",
      "Epoch 4/50\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.9551 - accuracy: 0.7116 - val_loss: 4.1863 - val_accuracy: 0.6484\n",
      "Epoch 5/50\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.4949 - accuracy: 0.7487 - val_loss: 3.8463 - val_accuracy: 0.6553\n",
      "Epoch 6/50\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.3020 - accuracy: 0.7764 - val_loss: 4.1066 - val_accuracy: 0.6543\n",
      "Epoch 7/50\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.6522 - accuracy: 0.7406 - val_loss: 4.4616 - val_accuracy: 0.6865\n",
      "Epoch 8/50\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.2758 - accuracy: 0.8086 - val_loss: 3.7697 - val_accuracy: 0.6592\n",
      "Epoch 9/50\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.3937 - accuracy: 0.8021 - val_loss: 3.7858 - val_accuracy: 0.6904\n",
      "Epoch 10/50\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 0.8692 - accuracy: 0.8434 - val_loss: 3.8578 - val_accuracy: 0.7236\n",
      "Epoch 11/50\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 1.1418 - accuracy: 0.8258 - val_loss: 3.9621 - val_accuracy: 0.6982\n",
      "Epoch 12/50\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 1.0506 - accuracy: 0.8190 - val_loss: 3.9703 - val_accuracy: 0.7061\n",
      "Epoch 13/50\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 0.9903 - accuracy: 0.8405 - val_loss: 4.6140 - val_accuracy: 0.7021\n",
      "Epoch 14/50\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 0.9308 - accuracy: 0.8434 - val_loss: 4.6106 - val_accuracy: 0.7158\n",
      "Epoch 15/50\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 0.6295 - accuracy: 0.8779 - val_loss: 4.2359 - val_accuracy: 0.7188\n",
      "Epoch 16/50\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.8547 - accuracy: 0.8581 - val_loss: 4.6990 - val_accuracy: 0.6865\n",
      "Epoch 17/50\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.5243 - accuracy: 0.8988 - val_loss: 3.9969 - val_accuracy: 0.7539\n",
      "Epoch 18/50\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.5711 - accuracy: 0.8818 - val_loss: 4.1975 - val_accuracy: 0.7344\n",
      "Epoch 19/50\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.6905 - accuracy: 0.8848 - val_loss: 5.3418 - val_accuracy: 0.6670\n",
      "Epoch 20/50\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.2955 - accuracy: 0.8226 - val_loss: 5.2773 - val_accuracy: 0.6953\n",
      "Epoch 21/50\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.1106 - accuracy: 0.8483 - val_loss: 5.7102 - val_accuracy: 0.6631\n",
      "Epoch 22/50\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.0532 - accuracy: 0.8779 - val_loss: 4.9329 - val_accuracy: 0.7256\n",
      "Epoch 23/50\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.6278 - accuracy: 0.8955 - val_loss: 5.5118 - val_accuracy: 0.7109\n",
      "Epoch 24/50\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.6144 - accuracy: 0.9076 - val_loss: 5.6804 - val_accuracy: 0.7080\n",
      "Epoch 25/50\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.4608 - accuracy: 0.9059 - val_loss: 4.9977 - val_accuracy: 0.7207\n",
      "Epoch 26/50\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.6215 - accuracy: 0.9007 - val_loss: 5.7398 - val_accuracy: 0.7178\n",
      "Epoch 27/50\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.4744 - accuracy: 0.9082 - val_loss: 5.5083 - val_accuracy: 0.7441\n",
      "Epoch 28/50\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.8692 - accuracy: 0.8766 - val_loss: 6.2268 - val_accuracy: 0.7334\n",
      "Epoch 29/50\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.0984 - accuracy: 0.8617 - val_loss: 6.3776 - val_accuracy: 0.7188\n",
      "Epoch 30/50\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.9127 - accuracy: 0.8848 - val_loss: 6.0942 - val_accuracy: 0.7080\n",
      "Epoch 31/50\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.5259 - accuracy: 0.9066 - val_loss: 5.8990 - val_accuracy: 0.7461\n",
      "Epoch 32/50\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.5581 - accuracy: 0.9196 - val_loss: 5.4316 - val_accuracy: 0.7852\n",
      "Epoch 33/50\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.3495 - accuracy: 0.9434 - val_loss: 5.5100 - val_accuracy: 0.7666\n",
      "Epoch 34/50\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.6264 - accuracy: 0.9030 - val_loss: 5.7981 - val_accuracy: 0.7500\n",
      "Epoch 35/50\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.3848 - accuracy: 0.9307 - val_loss: 6.2590 - val_accuracy: 0.7168\n",
      "Epoch 36/50\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.5314 - accuracy: 0.9089 - val_loss: 6.1109 - val_accuracy: 0.7305\n",
      "Epoch 37/50\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.5311 - accuracy: 0.9193 - val_loss: 6.1213 - val_accuracy: 0.7598\n",
      "Epoch 38/50\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.5675 - accuracy: 0.9180 - val_loss: 7.1466 - val_accuracy: 0.7295\n",
      "Epoch 39/50\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.5607 - accuracy: 0.9215 - val_loss: 5.9763 - val_accuracy: 0.7568\n",
      "Epoch 40/50\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.4598 - accuracy: 0.9333 - val_loss: 5.5354 - val_accuracy: 0.7676\n",
      "Epoch 41/50\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.6975 - accuracy: 0.9163 - val_loss: 7.2308 - val_accuracy: 0.7188\n",
      "Epoch 42/50\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.6907 - accuracy: 0.9053 - val_loss: 5.7918 - val_accuracy: 0.7520\n",
      "Epoch 43/50\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.6994 - accuracy: 0.9258 - val_loss: 6.2828 - val_accuracy: 0.7607\n",
      "Epoch 44/50\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.5571 - accuracy: 0.9255 - val_loss: 6.4898 - val_accuracy: 0.7520\n",
      "Epoch 45/50\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.5608 - accuracy: 0.9245 - val_loss: 6.9303 - val_accuracy: 0.7383\n",
      "Epoch 46/50\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.6525 - accuracy: 0.8997 - val_loss: 6.2535 - val_accuracy: 0.7441\n",
      "Epoch 47/50\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.5782 - accuracy: 0.9157 - val_loss: 6.8728 - val_accuracy: 0.7588\n",
      "Epoch 48/50\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.3060 - accuracy: 0.9525 - val_loss: 7.0800 - val_accuracy: 0.7627\n",
      "Epoch 49/50\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.2058 - accuracy: 0.9508 - val_loss: 6.7868 - val_accuracy: 0.7588\n",
      "Epoch 50/50\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.2112 - accuracy: 0.9531 - val_loss: 6.5452 - val_accuracy: 0.7842\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 50\n",
    "history = model_instr_lr.fit(\n",
    "    x=spectrograms_train,\n",
    "    y=labels_instr_train,\n",
    "    validation_data=(spectrograms_test, labels_instr_test),\n",
    "    epochs=EPOCHS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/instr_lr\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/instr_lr\\assets\n"
     ]
    }
   ],
   "source": [
    "save_as_json(history.history, \"training_history/instr_lr.json\")\n",
    "model_instr_lr.save(\"./models/instr_lr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_6 (Conv1D)           (None, 63998, 32)         128       \n",
      "                                                                 \n",
      " max_pooling1d_6 (MaxPooling  (None, 31999, 32)        0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_7 (Conv1D)           (None, 31997, 64)         6208      \n",
      "                                                                 \n",
      " max_pooling1d_7 (MaxPooling  (None, 15998, 64)        0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 15998, 64)         0         \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 1023872)           0         \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 1023872)           0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 3071619   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,077,955\n",
      "Trainable params: 3,077,955\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_src_cnn = models.Sequential([\n",
    "    layers.Input(shape=audio_train.shape[1:]),\n",
    "    layers.Conv1D(32, 3, activation='relu'),\n",
    "    layers.MaxPooling1D(),\n",
    "    layers.Conv1D(64, 3, activation='relu'),\n",
    "    layers.MaxPooling1D(),\n",
    "    layers.Dropout(0.25),\n",
    "    layers.Flatten(),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(len(sources)),\n",
    "])\n",
    "\n",
    "model_src_cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_src_cnn.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "96/96 [==============================] - 14s 142ms/step - loss: 1.2731 - accuracy: 0.5078 - val_loss: 0.8735 - val_accuracy: 0.6201\n",
      "Epoch 2/50\n",
      "96/96 [==============================] - 13s 141ms/step - loss: 0.6611 - accuracy: 0.7067 - val_loss: 0.6509 - val_accuracy: 0.7090\n",
      "Epoch 3/50\n",
      "96/96 [==============================] - 14s 146ms/step - loss: 0.4529 - accuracy: 0.8164 - val_loss: 0.5912 - val_accuracy: 0.7549\n",
      "Epoch 4/50\n",
      "96/96 [==============================] - 14s 141ms/step - loss: 0.3336 - accuracy: 0.8672 - val_loss: 0.5984 - val_accuracy: 0.7617\n",
      "Epoch 5/50\n",
      "96/96 [==============================] - 14s 143ms/step - loss: 0.2207 - accuracy: 0.9242 - val_loss: 0.6249 - val_accuracy: 0.7656\n",
      "Epoch 6/50\n",
      "96/96 [==============================] - 14s 143ms/step - loss: 0.1897 - accuracy: 0.9313 - val_loss: 0.7151 - val_accuracy: 0.7656\n",
      "Epoch 7/50\n",
      "96/96 [==============================] - 14s 147ms/step - loss: 0.1494 - accuracy: 0.9544 - val_loss: 1.0200 - val_accuracy: 0.7422\n",
      "Epoch 8/50\n",
      "96/96 [==============================] - 14s 146ms/step - loss: 0.1199 - accuracy: 0.9616 - val_loss: 0.8503 - val_accuracy: 0.7715\n",
      "Epoch 9/50\n",
      "96/96 [==============================] - 14s 146ms/step - loss: 0.1283 - accuracy: 0.9577 - val_loss: 0.8524 - val_accuracy: 0.7646\n",
      "Epoch 10/50\n",
      "96/96 [==============================] - 14s 146ms/step - loss: 0.1738 - accuracy: 0.9567 - val_loss: 1.8835 - val_accuracy: 0.6689\n",
      "Epoch 11/50\n",
      "96/96 [==============================] - 14s 144ms/step - loss: 0.1451 - accuracy: 0.9583 - val_loss: 0.7692 - val_accuracy: 0.7705\n",
      "Epoch 12/50\n",
      "96/96 [==============================] - 14s 146ms/step - loss: 0.0521 - accuracy: 0.9909 - val_loss: 0.8689 - val_accuracy: 0.7871\n",
      "Epoch 13/50\n",
      "96/96 [==============================] - 14s 148ms/step - loss: 0.0561 - accuracy: 0.9840 - val_loss: 1.0632 - val_accuracy: 0.7783\n",
      "Epoch 13: early stopping\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 50\n",
    "history = model_src_cnn.fit(\n",
    "    x=audio_train,\n",
    "    y=labels_src_train,\n",
    "    validation_data=(audio_test, labels_src_test),\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=tf.keras.callbacks.EarlyStopping(verbose=1, patience=5),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/src_cnn\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/src_cnn\\assets\n"
     ]
    }
   ],
   "source": [
    "save_as_json(history.history, \"training_history/src_cnn.json\")\n",
    "model_src_cnn.save(\"./models/src_cnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_9 (Flatten)         (None, 64000)             0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 3)                 192003    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 192,003\n",
      "Trainable params: 192,003\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_src_lr = models.Sequential([\n",
    "    layers.Input(shape=audio_train.shape[1:]),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(len(sources)),\n",
    "])\n",
    "\n",
    "model_src_lr.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_src_lr.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 1.4118 - accuracy: 0.5130 - val_loss: 1.3721 - val_accuracy: 0.5459\n",
      "Epoch 2/50\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.7705 - accuracy: 0.7653 - val_loss: 1.6196 - val_accuracy: 0.5684\n",
      "Epoch 3/50\n",
      "96/96 [==============================] - 1s 6ms/step - loss: 0.5945 - accuracy: 0.8236 - val_loss: 1.5393 - val_accuracy: 0.5840\n",
      "Epoch 4/50\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.4862 - accuracy: 0.8571 - val_loss: 1.6558 - val_accuracy: 0.5830\n",
      "Epoch 5/50\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.4625 - accuracy: 0.8727 - val_loss: 1.8472 - val_accuracy: 0.5840\n",
      "Epoch 6/50\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.3930 - accuracy: 0.8883 - val_loss: 1.8463 - val_accuracy: 0.5850\n",
      "Epoch 7/50\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.3167 - accuracy: 0.9111 - val_loss: 2.0294 - val_accuracy: 0.5840\n",
      "Epoch 8/50\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.2839 - accuracy: 0.9235 - val_loss: 2.1219 - val_accuracy: 0.5859\n",
      "Epoch 9/50\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.2842 - accuracy: 0.9225 - val_loss: 2.2408 - val_accuracy: 0.5811\n",
      "Epoch 10/50\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.2487 - accuracy: 0.9349 - val_loss: 2.2548 - val_accuracy: 0.5742\n",
      "Epoch 11/50\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.2564 - accuracy: 0.9388 - val_loss: 2.3222 - val_accuracy: 0.5840\n",
      "Epoch 11: early stopping\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 50\n",
    "history = model_src_lr.fit(\n",
    "    x=audio_train,\n",
    "    y=labels_src_train,\n",
    "    validation_data=(audio_test, labels_src_test),\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=tf.keras.callbacks.EarlyStopping(verbose=1, patience=10),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/src_lr\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/src_lr\\assets\n"
     ]
    }
   ],
   "source": [
    "save_as_json(history.history, \"training_history/src_lr.json\")\n",
    "model_src_lr.save(\"./models/src_lr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audioml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
